å¤ä¹ äº†æ‰€æœ‰çŸ¥è¯†ç‚¹ï¼Œä¸€åˆ‡éƒ½å‡†å¤‡å°±ç»ªï¼Œé‚£å°±å¼€å§‹å†™å±äºä½ çš„ç½‘é¡µå§ï¼
æˆ‘å·²ç»æŠŠç½‘é¡µçš„HTMLæºä»£ç å‡†å¤‡å¥½äº†ï¼Œä½ ç›´æ¥åœ¨ä¸Šé¢ä¿®æ”¹å°±å¥½ã€‚
ç°åœ¨ï¼Œè¯·æŠŠç½‘é¡µ
[è¿™ä¸ªä¹¦é™¢ä¸å¤ªå†·5.0](https://localprod.pandateacher.com/python-manuscript/crawler-html/spider-men5.0.html)
ä¿®æ”¹ä¸ºä½ å–œæ¬¢çš„æ¨¡æ ·ã€‚
â€¨
å¿…åšï¼š
- ä¿®æ”¹ç½‘é¡µæ ‡é¢˜
- å¢åŠ è‡³å°‘ä¸€æœ¬ä¹¦çš„æè¿°
- ä¿®æ”¹ç½‘é¡µåº•éƒ¨
â€¨
é€‰åšï¼š
- ä¿®æ”¹å·²æœ‰ä¹¦ç±çš„æè¿°
- å¢åŠ å¤šæœ¬ä¹¦çš„æè¿°
- è‡ªç”±åœ°åœ¨HTMLæ–‡æ¡£ä¸Šä¿®æ”¹ä»»æ„å†…å®¹
â€¨
ã€æç¤ºã€‘
â€¨
ç½‘é¡µç»“æ„ä¿®æ”¹ï¼š
ä¸ºäº†è®©ç½‘é¡µçš„ç»“æ„æ›´åŠ æ¸…æ™°ï¼Œå¯ä»¥æŠŠæ¯ä¸€æœ¬ä¹¦éƒ½å†™æˆä¸€ä¸ª`<div>`å…ƒç´ ã€‚
ç»†èŠ‚çš„ä¿®æ”¹ï¼š
ä¹¦ç±å°é¢å›¾ç‰‡çš„URLï¼Œä½ å¯ä»¥è¯•è¯•ç”¨è±†ç“£ä¹¦ç±ä¸»é¡µçš„å›¾ç‰‡ã€‚å³é”®ç‚¹å‡»å›¾ç‰‡ï¼Œç„¶åé€‰æ‹©ã€å¤åˆ¶å›¾ç‰‡åœ°å€ã€‘(https://res.pandateacher.com/2019-01-12-21-30-00.png)
â€¨
ã€è§£ç­”ã€‘
ä½ çš„ä¹¦è‹‘ä½ åšä¸»ã€‚
è¿™æ˜¯æˆ‘ç»™ä½ çš„å‚è€ƒç­”æ¡ˆï¼Œä½ å¯ä»¥ç‚¹å¼€ä¸‹é¢çš„é“¾æ¥çœ‹çœ‹ï¼š
https://localprod.pandateacher.com/python-manuscript/crawler-html/exercise/01-01-test.html






________________________________________________________________________________________________




ç»ƒä¹ -åšå®¢çˆ¬è™«

é¢˜ç›®è¦æ±‚ï¼š
ä½ éœ€è¦çˆ¬å–çš„æ˜¯åšå®¢ã€äººäººéƒ½æ˜¯èœ˜è››ä¾ ã€‘ä¸­ï¼Œã€Šæœªæ¥å·²æ¥ï¼ˆå››ï¼‰â€”â€”Pythonå­¦ä¹ è¿›é˜¶å›¾è°±ã€‹çš„æ‰€æœ‰æ–‡ç« è¯„è®ºï¼Œå¹¶ä¸”æ‰“å°ã€‚

æ–‡ç« URL:
https://wordpress-edu-3autumn.localprod.forc.work/all-about-the-future_04/
â€¨
ã€æç¤ºã€‘
é¦–å…ˆï¼Œè®°å¾—è°ƒç”¨requestsåº“å’ŒBeautifulSoupæ¨¡å—
ç„¶åï¼ŒæŒ‰ç…§çˆ¬è™«çš„å››ä¸ªæ­¥éª¤æ¥å†™ä»£ç ï¼šï¼ˆä¸éœ€è¦å†™ç¬¬3æ­¥å­˜å‚¨æ•°æ®ï¼‰
ç¬¬0æ­¥ï¼šè·å–æ•°æ®
`requests.get()`
ç¬¬1æ­¥ï¼šè§£ææ•°æ®
`BeautifulSoup(ç½‘é¡µæºä»£ç çš„å­—ç¬¦ä¸²æ ¼å¼,'html.parser')`
ç¬¬2æ­¥ï¼šæå–æ•°æ®
`find_all()`
`for`å¾ªç¯éå†`list`
`Tag.text`
â€¨
ã€è§£ç­”ã€‘
é¦–å…ˆå¯¼å…¥ä¸¤ä¸ªæ¨¡å—ï¼Œç„¶åæŒ‰ç…§è·å–æ•°æ®ã€è§£ææ•°æ®ã€æå–æ•°æ®ä¸€æ­¥ä¸€æ­¥å†™ä¸‹æ¥å°±å¯ä»¥å•¦~



import requests # è°ƒç”¨requestsåº“

from bs4 import BeautifulSoup # è°ƒç”¨BeautifulSoupåº“

destnation_url = 'https://wordpress-edu-3autumn.localprod.forc.work/all-about-the-future_04/'

# æŠŠç½‘å€å¤åˆ¶ç»™å˜é‡destnation_url

destnation = requests.get (destnation_url) # è¿”å›ä¸€ä¸ªresponseå¯¹è±¡ï¼Œèµ‹å€¼ç»™destnation

soup = BeautifulSoup(destnation.text,'html.parser') # æŠŠç½‘é¡µè§£æä¸ºBeautifulSoupå¯¹è±¡

comments = soup.find_all('div',class_= 'comment-content') #é€šè¿‡åŒ¹é…å±æ€§æå–å‡ºæˆ‘ä»¬æƒ³è¦çš„å…ƒç´ 

for comment in comments: # éå†åˆ—è¡¨ï¼Œå–å‡ºåˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªå€¼

    print(comment.text) # æ‰“å°è¯„è®ºçš„æ–‡æœ¬


________________________________________________________________________________________________


ç»ƒä¹ -ä¹¦åº—å¯»å®
â€¨
1.ç¬¬ä¸€ä¸ªå°ç»ƒä¹ 
é¢˜ç›®è¦æ±‚ï¼šä½ éœ€è¦çˆ¬å–çš„æ˜¯ç½‘ä¸Šä¹¦åº—(http://books.toscrape.com/)ä¸­æ‰€æœ‰ä¹¦çš„åˆ†ç±»ç±»å‹ï¼Œå¹¶ä¸”å°†å®ƒä»¬æ‰“å°å‡ºæ¥ã€‚ç½‘é¡µURL:http://books.toscrape.com/
â€¨
ã€æç¤ºã€‘
â€¨
è¦æ‰¾åˆ°å°±éœ€è¦å…ˆæ‰¾åˆ°æ‰€æœ‰çš„liæ ‡ç­¾ï¼Œä»”ç»†çœ‹HTMLæºä»£ç çš„ç»“æ„ï¼Œè¿™é‡Œéœ€è¦åµŒå¥—æå–å¥½å‡ å±‚ï¼š
`find('ul',class_='nav').find('ul').find_all('li')`
æœ€ç»ˆæ‰“å°ç»“æœï¼Œå¯ä»¥ä½¿ç”¨`str.strip()`å»é™¤ç‰¹æ®Šå­—ç¬¦ä¸²ã€‚
æ¯”å¦‚ï¼Œä½¿ç”¨`.strip()`å³å¯å»æ‰'Â  Â æˆ‘æ˜¯å´æ«\n'æ–‡å­—å‰é¢çš„ç©ºæ ¼ä¸åé¢çš„æ¢è¡Œã€‚
â€¨
import requests
from bs4 import BeautifulSoup


res_bookstore = requests.get('http://books.toscrape.com/')
bs_bookstore = BeautifulSoup(res_bookstore.text,'html.parser')
list_kind = bs_bookstore.find('ul',class_='nav').find('ul').find_all('li') # è¿™é‡Œéœ€è¦æå–å¥½å‡ å±‚


for tag_kind in list_kind:
Â  Â  tag_name = tag_kind.find('a')
Â  Â  print(tag_name.text.strip()) # å»é™¤ç‰¹æ®Šå­—ç¬¦ä¸²ï¼Œæ¯”å¦‚ç©ºæ ¼ï¼Œ\nï¼Œ\tç­‰ç­‰





________________________________________________________________________________________________



ç¬¬äºŒä¸ªå°ç»ƒä¹ 
â€¨
é¢˜ç›®è¦æ±‚ï¼šä½ éœ€è¦çˆ¬å–çš„æ˜¯ç½‘ä¸Šä¹¦åº—[Books to Scrape](http://books.toscrape.com/)Travelè¿™ç±»ä¹¦ä¸­ï¼Œæ‰€æœ‰ä¹¦çš„ä¹¦åã€è¯„åˆ†ã€ä»·æ ¼ä¸‰ç§ä¿¡æ¯ï¼Œå¹¶ä¸”æ‰“å°æå–åˆ°çš„ä¿¡æ¯ã€‚
ç½‘é¡µURL:http://books.toscrape.com/catalogue/category/books/travel_2/index.html
åœ¨æ­¤ï¼Œæå–ä¹¦åå’Œè¯„åˆ†éƒ½æœ‰ä¸€å®šéš¾åº¦ï¼Œæƒ³ä¸åˆ°æ€ä¹ˆåšï¼ŸæŸ¥çœ‹æç¤ºã€‚
â€¨
ã€æç¤ºã€‘
1.æå–ä¹¦åï¼š
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`<a>`æ ‡ç­¾ä¸­çš„æ–‡å­—å†…å®¹æ‰€æ˜¾ç¤ºçš„ä¸æ˜¯å®Œæ•´ä¹¦åï¼Œå®Œæ•´çš„ä¹¦åæ˜¯`<a>`æ ‡ç­¾ä¸­ï¼Œ`<title>`å±æ€§çš„å€¼ã€‚
å› æ­¤éœ€è¦ç”¨åˆ°`tag['å±æ€§å']`æ¥æå–å±æ€§å€¼ã€‚
â€¨
2.æå–è¯„åˆ†ï¼š
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯„åˆ†è—åœ¨äº†`<p>`æ ‡ç­¾çš„`<class>`å±æ€§ä¸­ï¼Œå®ƒæ˜¯`<class>`çš„ç¬¬1ä¸ªå±æ€§å€¼ã€‚
æˆ‘ä»¬éœ€è¦æ ¹æ®`<class>`çš„ç¬¬0ä¸ªå±æ€§å€¼`<star-rating>`æå‡ºå®ƒçš„ç¬¬1ä¸ªå±æ€§å€¼ã€‚


import requests
from bs4 import BeautifulSoup


res_bookstore = requests.get('http://books.toscrape.com/catalogue/category/books/travel_2/index.html')
bs_bookstore = BeautifulSoup(res_bookstore.text,'html.parser')
list_books = bs_bookstore.find_all(class_='product_pod')
for tag_books in list_books:
Â  Â  tag_name = tag_books.find('h3').find('a') # æ‰¾åˆ°aæ ‡ç­¾éœ€è¦æå–ä¸¤æ¬¡
Â  Â  list_star = tag_books.find('p',class_="star-rating")
Â  Â  # è¿™ä¸ªpæ ‡ç­¾çš„classå±æ€§æœ‰ä¸¤ç§ï¼š"star-rating"ï¼Œä»¥åŠå…·ä½“çš„å‡ æ˜Ÿæ¯”å¦‚"Two"ã€‚æˆ‘ä»¬é€‰æ‹©æ‰€æœ‰ä¹¦éƒ½æœ‰çš„classå±æ€§ï¼š"star-rating"
Â  Â  tag_price = tag_books.find('p',class_="price_color") # ä»·æ ¼æ¯”è¾ƒå¥½æ‰¾ï¼Œæ ¹æ®å±æ€§æå–ï¼Œæˆ–è€…æ ‡ç­¾ä¸å±æ€§ä¸€èµ·éƒ½å¯ä»¥
Â  Â  print(tag_name['title']) # è¿™é‡Œç”¨åˆ°äº†tag['å±æ€§å']æå–å±æ€§å€¼
Â  Â  print('star-rating:',list_star['class'][1])
Â  Â  # åŒæ ·æ˜¯ç”¨å±æ€§åæå–å±æ€§å€¼
Â  Â  # ç”¨list_star['class']æå–å‡ºæ¥ä¹‹åæ˜¯ä¸€ä¸ªç”±ä¸¤ä¸ªå€¼ç»„æˆçš„åˆ—è¡¨ï¼Œå¦‚ï¼š"['star-rating', 'Two']"ï¼Œæˆ‘ä»¬æœ€ç»ˆè¦æå–çš„æ˜¯è¿™ä¸ªåˆ—è¡¨çš„ç¬¬1ä¸ªå€¼ï¼š"Two"ã€‚
Â  Â  # ä¸ºä»€ä¹ˆæ˜¯åˆ—è¡¨å‘¢ï¼Ÿå› ä¸ºè¿™é‡Œçš„classå±æ€§æœ‰ä¸¤ä¸ªå€¼ã€‚å…¶å®ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ˜¯ä½¿ç”¨classå±æ€§çš„ç¬¬ä¸€ä¸ªå€¼æå–å‡ºäº†ç¬¬äºŒä¸ªå€¼ã€‚
Â  Â  print('Price:',tag_price.text, end='\n'+'------'+'\n') # æ‰“å°çš„æ—¶å€™ï¼Œæˆ‘åŠ ä¸Šäº†æ¢è¡Œï¼Œä¸ºäº†è®©æ•°æ®æ›´åŠ æ¸…æ™°åœ°åˆ†éš”å¼€ï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥ä¸åŠ ã€‚



________________________________________________________________________________________________



ç»ƒä¹ -åšå®¢æ–‡ç« -å‚è€ƒ
é¢˜ç›®è¦æ±‚ï¼šä½ éœ€è¦çˆ¬å–çš„æ˜¯åšå®¢(https://wordpress-edu-3autumn.localprod.forc.work/)ï¼Œé¦–é¡µçš„å››ç¯‡æ–‡ç« ä¿¡æ¯ï¼Œå¹¶ä¸”æ‰“å°æå–åˆ°çš„ä¿¡æ¯ã€‚
æå–æ¯ç¯‡æ–‡ç« çš„ï¼š
- æ–‡ç« æ ‡é¢˜
- å‘å¸ƒæ—¶é—´
- æ–‡ç« é“¾æ¥
ç½‘é¡µURL:https://spidermen.cn/
â€¨
ã€æç¤ºã€‘
æ–‡ç« é¢˜ç›®ä¸URLçš„æå–æ–¹å¼ç¨æœ‰ä¸åŒï¼š
``` html
<h2 class="entry-title">
Â  Â  <a href="https://wordpress-edu-3autumn.localprod.forc.work/all-about-the-future_04/" rel="bookmark">æœªæ¥å·²æ¥ï¼ˆå››ï¼‰â€”â€”Pythonå­¦ä¹ è¿›é˜¶å›¾è°±</a>
</h2>
```
æ–‡ç« æ ‡é¢˜å¯ä»¥é€šè¿‡`<h2>`ä¸`<class_="entry-title">`æ‰¾åˆ°ï¼Œå¹¶ç”¨`Tag.text`æå–å‡ºã€‚
è€Œæ–‡ç« URLå¿…é¡»å®šä½åˆ°`<a>`å…ƒç´ æ‰å¯ä»¥ã€‚
â€¨

import requests
from bs4 import BeautifulSoup


url_destnation = 'https://spidermen.cn/'
res_destnation = requests.get (url_destnation)
print(res_destnation.status_code) # æ‰“å°å“åº”ç 


bs_articles = BeautifulSoup(res_destnation.text,'html.parser')
list_articles = bs_articles.find_all('header', class_ = "entry-header") # é¦–å…ˆæ‰¾åˆ°æ¯ç¯‡æ–‡ç« æ‰€åœ¨çš„ç›¸åŒçš„å…ƒç´ 
for tag_article in list_articles: # éå†åˆ—è¡¨
Â  Â  tag_title = tag_article.find('h2',class_ = "entry-title") # æ‰¾æ–‡ç« æ ‡é¢˜
Â  Â  tag_url = tag_article.find('a',rel = "bookmark")Â  # æ‰¾æ–‡ç« é“¾æ¥
Â  Â  tag_date = tag_article.find('time',class_="entry-date published") # æ‰¾æ–‡ç« å‘å¸ƒæ—¶é—´
Â  Â  print(tag_title.text,'å‘å¸ƒäºï¼š',tag_date.text) # æ‰“å°æ–‡ç« æ ‡é¢˜ä¸å‘å¸ƒæ—¶é—´
Â  Â  print(tag_url['href'])Â  # æ¢è¡Œæ‰“å°æ–‡ç« é“¾æ¥ï¼Œéœ€è¦ä½¿ç”¨å±æ€§åæå–å±æ€§å€¼




________________________________________________________________________________________________

ç»ƒä¹ -è±†ç“£çˆ¬è™«
 ç¬¬ä¸€æ­¥ï¼šåˆ†æé—®é¢˜ï¼Œæ˜ç¡®ç»“æœ
é—®é¢˜éœ€æ±‚å°±æ˜¯æŠŠè±†ç“£TOP250é‡Œé¢çš„ åºå·/ç”µå½±å/è¯„åˆ†/æ¨èè¯­/é“¾æ¥ éƒ½çˆ¬å–ä¸‹æ¥ï¼Œç»“æœå°±æ˜¯å…¨éƒ¨å±•ç¤ºæ‰“å°å‡ºæ¥
â€¨
ã€è®²è§£ã€‘
é—®é¢˜éœ€æ±‚å°±æ˜¯æŠŠè±†ç“£TOP250é‡Œé¢çš„ åºå·/ç”µå½±å/è¯„åˆ†/æ¨èè¯­/é“¾æ¥ éƒ½çˆ¬å–ä¸‹æ¥ï¼Œç»“æœå°±æ˜¯å…¨éƒ¨å±•ç¤ºæ‰“å°å‡ºæ¥
â€¨
ç¬¬äºŒæ­¥ï¼šæ€è€ƒè¦ç”¨åˆ°çš„çŸ¥è¯†
è¦çˆ¬å–â€œåºå·/ç”µå½±å/è¯„åˆ†/æ¨èè¯­/é“¾æ¥â€è¿™äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº†ç”¨requests.get()è·å–æ•°æ®ï¼ŒBeautifulSoupåº“è§£ææ•°æ®ï¼Œfind()å’Œfind_all()æå–æ•°æ®ï¼Œè¿˜æœ‰å‘¢ï¼Œè§‚å¯Ÿä¸‹ï¼Œä¸€å…±10é¡µï¼Œæˆ‘ä»¬è¿˜è¦åŠ ä¸ªforå¾ªç¯å¯¹å§ï½ 
â€¨
ã€è®²è§£ã€‘
æ¥ä¸‹æ¥æˆ‘ä»¬ä¸€èµ·åˆ†æç½‘é¡µå§ï½
è¿›å…¥é¦–é¡µ https://movie.douban.com/top250?start=0&filter=  ï¼Œæ‰“å¼€æ£€æŸ¥å·¥å…·ï¼Œåœ¨Elementsé‡ŒæŸ¥çœ‹è¿™ä¸ªç½‘é¡µï¼Œæ˜¯ä»€ä¹ˆç»“æ„ã€‚ç‚¹å‡»å¼€å‘è€…å·¥å…·å·¦ä¸Šè§’çš„å°ç®­å¤´ï¼Œé€‰ä¸­â€œè‚–ç”³å…‹çš„æ•‘èµâ€ï¼Œè¿™æ ·å°±å®šä½äº†ç”µå½±åçš„æ‰€åœ¨ä½ç½®ï¼Œå®¡æŸ¥å…ƒç´ ä¸­æ˜¾ç¤º`<span class="title">`ï¼š`<span>`æ ‡ç­¾å†…çš„æ–‡æœ¬ï¼Œ`class`å±æ€§ï¼›æ¨èè¯­å’Œè¯„åˆ†ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œ`<span class='ing'>`ï¼Œ`<span class='rating_num'>`ï¼›åºå·ï¼š`<em class>`ï¼Œ`<em>`æ ‡ç­¾å†…çš„æ–‡æœ¬ï¼Œ`class`å±æ€§ï¼›æ¨èè¯­`<span class='ing'>`ï¼›é“¾æ¥æ˜¯`<a>`æ ‡ç­¾é‡Œ`href`çš„å€¼ã€‚æœ€åï¼Œå®ƒä»¬æœ€å°å…±åŒçˆ¶çº§æ ‡ç­¾ï¼Œæ˜¯`<li>`ã€‚
æˆ‘ä»¬å†æ¢ä¸ªç”µå½±éªŒè¯ä¸‹æ‰¾çš„è§„å¾‹æ˜¯å¦æ­£ç¡®ã€‚
checkåï¼Œæˆ‘ä»¬å†çœ‹ä¸€å…±10é¡µï¼Œæ¯é¡µçš„urlæœ‰ä»€ä¹ˆç›¸å…³å‘¢ï¼Ÿ
ç¬¬1é¡µï¼šhttps://movie.douban.com/top250?start=0&filter=
ç¬¬3é¡µï¼šhttps://movie.douban.com/top250?start=50&filter=
ç¬¬7é¡µï¼šhttps://movie.douban.com/top250?start=150&filter=
å‘ç°åªæœ‰startåé¢æ˜¯æœ‰å˜åŒ–å“’ï¼Œè§„å¾‹å°±æ˜¯ç¬¬Né¡µï¼Œstart=(N-1)*25 
åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§å†™çˆ¬è™«çš„æ€è·¯ã€‚
æ€è·¯ä¸€ï¼šå…ˆçˆ¬å–æœ€å°å…±åŒçˆ¶çº§æ ‡ç­¾ `<li>`ï¼Œç„¶åé’ˆå¯¹æ¯ä¸€ä¸ªçˆ¶çº§æ ‡ç­¾ï¼Œæå–é‡Œé¢çš„åºå·/ç”µå½±å/è¯„åˆ†/æ¨èè¯­/é“¾æ¥ã€‚
æ€è·¯äºŒï¼šåˆ†åˆ«æå–æ‰€æœ‰çš„åºå·/æ‰€æœ‰çš„ç”µå½±å/æ‰€æœ‰çš„è¯„åˆ†/æ‰€æœ‰çš„æ¨èè¯­/æ‰€æœ‰çš„é“¾æ¥ï¼Œç„¶åå†æŒ‰é¡ºåºä¸€ä¸€å¯¹åº”èµ·æ¥ã€‚
â€¨
ç¬¬ä¸‰æ­¥ï¼šä¹¦å†™æ€è·¯ä¸€ä»£ç 
å…ˆçˆ¬å–æœ€å°å…±åŒçˆ¶çº§æ ‡ç­¾`<li>`ï¼Œç„¶åé’ˆå¯¹æ¯ä¸€ä¸ªçˆ¶çº§æ ‡ç­¾ï¼Œæå–é‡Œé¢çš„åºå·/ç”µå½±å/è¯„åˆ†/æ¨èè¯­/é“¾æ¥


import requests, random, bs4

for x in range(10):
    url = 'https://movie.douban.com/top250?start=' + str(x*25) + '&filter='
    res = requests.get(url)
    bs = bs4.BeautifulSoup(res.text, 'html.parser')
    bs = bs.find('ol', class_="grid_view")
    for titles in bs.find_all('li'):
        num = titles.find('em',class_="").text
        #æŸ¥æ‰¾åºå·
        title = titles.find('span', class_="title").text
        #æŸ¥æ‰¾ç”µå½±å
        tes = titles.find('span',class_="inq").text
        #æŸ¥æ‰¾æ¨èè¯­
        comment = titles.find('span',class_="rating_num").text
        #æŸ¥æ‰¾è¯„åˆ†
        url_movie = titles.find('a')['href']
        
        print(num + '.' + title + 'â€”â€”' + comment + '\n' + 'æ¨èè¯­ï¼š' + tes +'\n' + url_movie)
       

çœ‹ç€æˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯ä¸€æ¡æ¡è¹¦å‡ºæ¥ï¼Œè¿˜æ˜¯å¾ˆå…´å¥‹å“’áƒš(â›â—¡â›âœ¿)áƒš è¯¶ï¼Œåˆ°222æ¡æ€ä¹ˆåœä¸‹æ¥æŠ¥é”™äº†å“ï¼Œä¸è¦æ…Œï½ 




      9         num = titles.find('em',class_="").text
     10         title = titles.find('span', class_="title").text
---> 11         tes = titles.find('span',class_="inq").text
     12         comment = titles.find('span',class_="rating_num").text
     13         url_movie = titles.find('a')['href']

AttributeError: 'NoneType' object has no attribute 'text'


çœ‹ä¸‹æŠ¥é”™ä¿¡æ¯â€œAttributeError: 'NoneType' object has no attribute 'text' â€ ï¼Œå®šä½åˆ°äº†tesè¿™ä¸€è¡Œï¼Œè¿™æ˜¯æ¨èè¯­å‘€ï¼Œä¸ºä»€ä¹ˆä¼šé”™å‘¢ï¼Ÿ æˆ‘ä»¬å›å½’ç½‘é¡µï¼Œå‘ç°ç¬¬223ä¸ªç”µå½±æ˜¯ã€Šä¸‰å—å¹¿å‘Šç‰Œã€‹ï¼Œè¯¶ï¼Œå®ƒç«Ÿç„¶æ²¡æœ‰æ¨èè¯­ï¼Œè€Œç©ºå€¼æ˜¯æ²¡åŠæ³•åštextæ–‡æœ¬è½¬æ¢çš„ï¼Œå› æ­¤æŠ¥é”™äº†å‘¢ã€‚
é‚£æ€ä¹ˆè§£å†³å‘¢ï¼Œèªæ˜çš„ä½ ä¸€å®šæƒ³åˆ°å•¦ï½  Bingoï¼ŒåŠ ä¸€ä¸ªåˆ¤æ–­å°±å¯ä»¥å•¦ï½ 
ä¿®æ”¹è¿‡ä»£ç ï¼Œæˆ‘ä»¬å†è¯•ä¸€ä¸‹å“¦ï½ 



import requests, random, bs4

for x in range(10):
    url = 'https://movie.douban.com/top250?start=' + str(x*25) + '&filter='
    res = requests.get(url)
    bs = bs4.BeautifulSoup(res.text, 'html.parser')
    bs = bs.find('ol', class_="grid_view")
    for titles in bs.find_all('li'):
        num = titles.find('em',class_="").text
        title = titles.find('span', class_="title").text
        comment = titles.find('span',class_="rating_num").text
        url_movie = titles.find('a')['href']
        
        if titles.find('span',class_="inq") != None:
            tes = titles.find('span',class_="inq").text
            print(num + '.' + title + 'â€”â€”' + comment + '\n' + 'æ¨èè¯­ï¼š' + tes +'\n' + url_movie)
        else:
            print(num + '.' + title + 'â€”â€”' + comment + '\n' +'\n' + url_movie)


å¥½å•¦ï¼Œ250ä¸ªç”µå½±çš„ä¿¡æ¯éƒ½æŠ“å–åˆ°äº†è€¶ï¼Œè€Œä¸”æˆ‘ä»¬å‘ç°ï¼Œç¬¬223å’Œ244éƒ½æ²¡æœ‰æ¨èè¯­ï¼Œåœ¨ç½‘é¡µæŸ¥çœ‹ä¸‹ä¹Ÿç¡®å®æ²¡æœ‰å‘¢ã€‚
æ€è·¯ä¸€æˆ‘ä»¬å·²ç»ä»£ç å®ç°å•¦ï¼Œä¸¾èµ·åŒæ‰‹ï¼Œæ‰“å¼€ï¼Œç»™è‡ªå·±æ”¾ä¸ªå°çƒŸèŠ±ğŸ†å§ï½
é‚£æ€è·¯äºŒå¯¹æˆ‘ä»¬æ¥è¯´ä¹Ÿæ˜¯å¾ˆè½»æ¾çš„äº‹æƒ…å•¦ï½ 

â€¨
ç¬¬å››æ­¥ï¼šä¹¦å†™æ€è·¯äºŒä»£ç 
åˆ†åˆ«æå–æ‰€æœ‰çš„åºå·/æ‰€æœ‰çš„ç”µå½±å/æ‰€æœ‰çš„è¯„åˆ†/æ‰€æœ‰çš„æ¨èè¯­/æ‰€æœ‰çš„é“¾æ¥ï¼Œç„¶åå†æŒ‰é¡ºåºä¸€ä¸€å¯¹åº”èµ·æ¥ã€‚


import requests
# å¼•ç”¨requestsæ¨¡å—
from bs4 import BeautifulSoup
for x in range(10):
url = 'https://movie.douban.com/top250?start=' + str(x*25) + '&filter='
res = requests.get(url)
bs = BeautifulSoup(res.text, 'html.parser')
tag_num = bs.find_all('div', class_="item")
# æŸ¥æ‰¾åŒ…å«åºå·ï¼Œç”µå½±åï¼Œé“¾æ¥çš„<div>æ ‡ç­¾
tag_comment = bs.find_all('div', class_='star')
# æŸ¥æ‰¾åŒ…å«è¯„åˆ†çš„<div>æ ‡ç­¾
tag_word = bs.find_all('span', class_='inq')
# æŸ¥æ‰¾æ¨èè¯­
print(len(tag_word),len(tag_num))

list_all = []
for x in range(len(tag_num)-1):
if tag_num[x].text[2:5] == '223' or tag_num[x].text[2:5] =='244':
list_movie = [tag_num[x].text[2:5], tag_num[x].find('img')['alt'], tag_comment[x].text[2:5], tag_num[x].find('a')['href'] ]
else:
list_movie = [tag_num[x].text[2:5], tag_num[x].find('img')['alt'], tag_comment[x].text[2:5], tag_word[x].text, tag_num[x].find('a')['href']]
list_all.append(list_movie)
print(list_all)



________________________________________________________________________________________________















